{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import csv\n",
    "import string\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "# change the seeting of the cells\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rjoin the two datasets\n",
    "\n",
    "( the new sentiment dataset, and the one saparted in the begining ) \n",
    "so it will be  (new_data = DATA2 + DATA1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejion DATA1 and DATA2 as a final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling ( optional for you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print summery of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning ( starts from here )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True) \n",
    "sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to rename some coulmn provided from twetter like these below ( and fill nan)\n",
    "\n",
    "#### like \n",
    "\n",
    "- created_at to date \n",
    "- screen_name to account name\n",
    "- in_reply_to_screen_name to replied_to\n",
    "\n",
    "\n",
    "##### and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename({'in_reply_to_screen_name': 'replied_to'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['replied_to'].fillna(\"nan\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['in_reply_to_user_id_str'].fillna(\"nan\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the source coulmn (to see from which device this tweeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"source\"] = data[\"source\"].str.extract('>(.+?)<', expand=False).str.strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count the locations ( this might be no accurate because some use the name of the city differently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['location'].fillna(\"Not given\", inplace=True)\n",
    "\n",
    "data.location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### change to date type, datetime and subset by weeks and days, hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the create_at column to datetime\n",
    "\n",
    "data['created_at'] = pd.to_datetime(data.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "\n",
    "#all date comes in UTC, so change dattime to saudi arabia \n",
    "\n",
    "data.created_at = data.created_at.dt.tz_convert('Asia/Riyadh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all data type are appropriate like integar and strings \n",
    "\n",
    "data['followers_count'] = data['followers_count'].astype(int)\n",
    "data['reply_count']= data['reply_count'].astype(int)\n",
    "data['retweet_count']= data['retweet_count'].astype(int)\n",
    "data['favorite_count']= data['favorite_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['replied_to']= data['replied_to'].astype(str)\n",
    "data['in_reply_to_user_id_str']= data['in_reply_to_user_id_str'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we create new columns to from the orginal time coulmn ( Month, Day, Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['by_hours'] = data.created_at.dt.hour\n",
    "data['by_day'] = data.created_at.dt.day_name()\n",
    "data['by_month'] = data.created_at.dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new columns to identify the time of the day tweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['by_hours'] = data['by_hours'].replace([4,5,6,7,8,9,10,11], \"Morning\")\n",
    "data['by_hours'] = data['by_hours'].replace([12,13,14,15,16, 17], \"AfterNoon\")\n",
    "data['by_hours'] = data['by_hours'].replace([18, 19,20,21, 22], \"Evening\")\n",
    "data['by_hours'] = data['by_hours'].replace([23,0,1,2,3], \"Late_night\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now feature enginnering part ( creating new columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After those steps above, now we need to know if it is retweet or non retweet Also the replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=[\"RT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rt(tweet):\n",
    "    label=\"Not a Retweet\"\n",
    "    for word in noise:\n",
    "        if word in tweet:\n",
    "            label=\"Retweet\"\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"retweet\"] = data['text'].apply(lambda x: find_rt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_replies(data):\n",
    "    if data[\"replied_to\"] == \"taqa_sa\":\n",
    "        return \"Yes\"\n",
    "    elif data[\"replied_to\"] == \"nan\":\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(replies_to=data.apply(find_replies, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now \n",
    "\n",
    "\n",
    "#### we have those new column:\n",
    "- year colum \n",
    "- month colum \n",
    "- day column \n",
    "- time of the day colum\n",
    "- retweet column \n",
    "- replied_to column\n",
    "\n",
    "\n",
    "### now is the time for visulaization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show replied_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0dbe1ca914d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replied_to'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['replied_to'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['retweet'].value_counts()\n",
    "\n",
    "# or you can the below \n",
    "\n",
    "data.retweet.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show reply count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reply_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reply verified and unverified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this will show the top 5 tweets got how number number of replies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nlargest(5, ['reply_count']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  this will show the top 5 tweets got how number number of favorite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nlargest(5, ['favorite_count']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this will show thenumber of source by each tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.source.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('where people tweet from:\\n{}'.format(data.source.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### those will show the tweets by day, hours ....etc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.by_day.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.by_hours.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['retweeted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['retweet_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['favorited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['favorite_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['favorite_count','retweet_count']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the tweets are:\\n{}'.format(data_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### additional code might be useful for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the number of replies and mentioned tweets during the campaign:\\n{}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some of the info above is already provided from tweeter and some are created by us, these will used for visuals into the platfom\n",
    "\n",
    "\n",
    "- number of verfied and unverfied pie ( Twitter provide this )\n",
    "- timeseries when those tweets tweeted [this is by year, month, day] ( we created this )\n",
    "- retweet ( we created this )\n",
    "- retweet_count ( Twitter provide this )\n",
    "- favorited ( Twitter provide this )\n",
    "- favorite_count ( Twitter provide this )\n",
    "- retweet_count ( Twitter provide this )\n",
    "- sentiment ( we created this )\n",
    "- category ( we created this )\n",
    "- word-cloud ( we created this)\n",
    "\n",
    "#### if you need any help in this please let me know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This below section beloing to the word cloud visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='sentiment',data=df)\n",
    "\n",
    "# Another chart a Funnel-Chart\n",
    "fig = go.Figure(go.Funnelarea(\n",
    "    text =df.sentiment,\n",
    "    values = df.text,\n",
    "    title = {\"position\": \"top center\", \"text\": \"----\"}\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fig = px.treemap(df, path=['Common_words'], values='count',title='---')\n",
    "fig.show()\n",
    "\n",
    "# Another chart \n",
    "fig = px.bar(df, x=\"count\", y=\"Common_words\", title='------', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()\n",
    "\n",
    "# bird Chart \n",
    "pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n",
    "plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from wordcloud import WordCloud\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def removeWeirdChars(text):\n",
    "    weridPatterns = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u'\\U00010000-\\U0010ffff'\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               u\"\\ufe0f\"\n",
    "                               u\"\\u2069\"\n",
    "                               u\"\\u2066\"\n",
    "                               u\"\\u200c\"\n",
    "                               u\"\\u2068\"\n",
    "                               u\"\\u2067\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return weridPatterns.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Visualize the 15 most frequent words used in all the tweets using a Word cloud.\n",
    "texts = ','.join(str(v) for v in newdata[\"text\"])\n",
    "te=removeWeirdChars(texts);\n",
    "reshaped_text = arabic_reshaper.reshape(te)\n",
    "bidi_text = get_display(reshaped_text)\n",
    "wordcloud = WordCloud(max_words=15,width=500, height=300, background_color=\"white\", font_path='/Users/nadaa/Downloads/noto-sans-arabic-ui-cn-xlt-c72da522a4/ArbFonts.com-(1)/ArbFONTS-NotoSansArabicUI-CondensedExtraLight.ttf').generate(bidi_text)\n",
    "wordcloud.to_file(\"Nada_worCloud.png\")\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion Of EDA - READ here for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
