{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nadaa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import   RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# --------------------------------------- #\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "from pyarabic.araby import strip_tatweel\n",
    "from pyarabic.araby import tokenize, is_arabicrange, strip_tashkeel\n",
    "# --------------------------------------- #\n",
    "import pyarabic.arabrepr\n",
    "arepr = pyarabic.arabrepr.ArabicRepr()\n",
    "repr = arepr.repr\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "import emoji\n",
    "\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading the new data\n",
    "\n",
    "- note: you may read the data differently , this is an example to show you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('End_of_campaign_Hashtag.csv' ,names=[\"created_at\", \"source\", \"screen_name\", 'followers_count',\"location\",\n",
    "                                        \"verified\",'in_reply_to_screen_name',\"in_reply_to_user_id_str\",\"reply_count\",\n",
    "                                        \"retweet_count\",\"favorite_count\",\"lang\",\"favorited\",\"retweeted\",\"addition_data\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>addition_data</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Nov 24 19:10:31 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>M_World2020</td>\n",
       "      <td>17</td>\n",
       "      <td>Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...</td>\n",
       "      <td>RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Nov 24 19:08:33 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>B7Kgsvd72R2jzNL</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Nov 24 19:00:02 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Abohedab1</td>\n",
       "      <td>301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>RT @taqa_sa: Ø§Ù„Ø¬Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ø§Ø± ÙˆØ§Ù„Ø£Ø®Ø¶Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø­Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Nov 24 18:42:07 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Hanoma29441020</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Nov 24 18:41:22 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>560Mohammad</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...</td>\n",
       "      <td>RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>Fri Oct 30 08:32:56 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>nooo0011211</td>\n",
       "      <td>555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>RT @taqa_sa: Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8176</th>\n",
       "      <td>Fri Oct 30 08:32:42 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>44PROFESSOR44</td>\n",
       "      <td>29</td>\n",
       "      <td>âš”ï¸ğŸ‡¸ğŸ‡¦Ø¢Ù„Ù…ÛØ¯ÙŠÛÙ†Ø© Ø¢Ù„Ù…ÛÙ†ÙˆØ±Ø©ğŸ‡¸ğŸ‡¦âš”ï¸</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>RT @taqa_sa: Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>Fri Oct 30 08:30:00 +0000 2020</td>\n",
       "      <td>&lt;a href=\"https://ads.twitter.com\" rel=\"nofollo...</td>\n",
       "      <td>taqa_sa</td>\n",
       "      <td>283080</td>\n",
       "      <td>Kingdom of Saudi Arabia</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475</td>\n",
       "      <td>400</td>\n",
       "      <td>4319</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>Thu Oct 29 04:56:16 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>ii_B93</td>\n",
       "      <td>240</td>\n",
       "      <td>Ø£Ø³ÙƒÙ† Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØªØ³ÙƒÙ†Ù†ÙŠâ¤ï¸</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>#ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª\\nØ­Ø¨Ù‘ÙŠØª Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ â¤ï¸â¤ï¸ http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8179</th>\n",
       "      <td>Mon Oct 26 15:04:01 +0000 2020</td>\n",
       "      <td>&lt;a href=\"https://jamiemagee.dk\" rel=\"nofollow\"...</td>\n",
       "      <td>HashflagArchive</td>\n",
       "      <td>7290</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>#ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª https://t.co/LleXgDcyqg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8180 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at  \\\n",
       "0     Tue Nov 24 19:10:31 +0000 2020   \n",
       "1     Tue Nov 24 19:08:33 +0000 2020   \n",
       "2     Tue Nov 24 19:00:02 +0000 2020   \n",
       "3     Tue Nov 24 18:42:07 +0000 2020   \n",
       "4     Tue Nov 24 18:41:22 +0000 2020   \n",
       "...                              ...   \n",
       "8175  Fri Oct 30 08:32:56 +0000 2020   \n",
       "8176  Fri Oct 30 08:32:42 +0000 2020   \n",
       "8177  Fri Oct 30 08:30:00 +0000 2020   \n",
       "8178  Thu Oct 29 04:56:16 +0000 2020   \n",
       "8179  Mon Oct 26 15:04:01 +0000 2020   \n",
       "\n",
       "                                                 source      screen_name  \\\n",
       "0     <a href=\"http://twitter.com/download/android\" ...      M_World2020   \n",
       "1     <a href=\"http://twitter.com/download/iphone\" r...  B7Kgsvd72R2jzNL   \n",
       "2     <a href=\"http://twitter.com/download/android\" ...        Abohedab1   \n",
       "3     <a href=\"http://twitter.com/download/android\" ...   Hanoma29441020   \n",
       "4     <a href=\"http://twitter.com/download/android\" ...      560Mohammad   \n",
       "...                                                 ...              ...   \n",
       "8175  <a href=\"http://twitter.com/download/android\" ...      nooo0011211   \n",
       "8176  <a href=\"http://twitter.com/download/android\" ...    44PROFESSOR44   \n",
       "8177  <a href=\"https://ads.twitter.com\" rel=\"nofollo...          taqa_sa   \n",
       "8178  <a href=\"http://twitter.com/download/iphone\" r...           ii_B93   \n",
       "8179  <a href=\"https://jamiemagee.dk\" rel=\"nofollow\"...  HashflagArchive   \n",
       "\n",
       "      followers_count                    location  verified  \\\n",
       "0                  17    Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©     False   \n",
       "1                  22                         NaN     False   \n",
       "2                 301                         NaN     False   \n",
       "3                  69                         NaN     False   \n",
       "4                  87                         NaN     False   \n",
       "...               ...                         ...       ...   \n",
       "8175              555                         NaN     False   \n",
       "8176               29  âš”ï¸ğŸ‡¸ğŸ‡¦Ø¢Ù„Ù…ÛØ¯ÙŠÛÙ†Ø© Ø¢Ù„Ù…ÛÙ†ÙˆØ±Ø©ğŸ‡¸ğŸ‡¦âš”ï¸     False   \n",
       "8177           283080     Kingdom of Saudi Arabia      True   \n",
       "8178              240      Ø£Ø³ÙƒÙ† Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØªØ³ÙƒÙ†Ù†ÙŠâ¤ï¸     False   \n",
       "8179             7290                     Twitter     False   \n",
       "\n",
       "     in_reply_to_screen_name  in_reply_to_user_id_str  reply_count  \\\n",
       "0                        NaN                      NaN            0   \n",
       "1                        NaN                      NaN            0   \n",
       "2                        NaN                      NaN            0   \n",
       "3                        NaN                      NaN            0   \n",
       "4                        NaN                      NaN            0   \n",
       "...                      ...                      ...          ...   \n",
       "8175                     NaN                      NaN            0   \n",
       "8176                     NaN                      NaN            0   \n",
       "8177                     NaN                      NaN          475   \n",
       "8178                     NaN                      NaN            1   \n",
       "8179                     NaN                      NaN            0   \n",
       "\n",
       "      retweet_count  favorite_count lang  favorited  retweeted  \\\n",
       "0                 0               0  und      False      False   \n",
       "1                 0               0   ar      False      False   \n",
       "2                 0               0   ar      False      False   \n",
       "3                 0               0   ar      False      False   \n",
       "4                 0               0  und      False      False   \n",
       "...             ...             ...  ...        ...        ...   \n",
       "8175              0               0   ar      False      False   \n",
       "8176              0               0   ar      False      False   \n",
       "8177            400            4319   ar      False      False   \n",
       "8178              0               0   ar      False      False   \n",
       "8179              0               1  und      False      False   \n",
       "\n",
       "                                          addition_data  \\\n",
       "0     {'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...   \n",
       "1     {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "2     {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "3     {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "4     {'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...   \n",
       "...                                                 ...   \n",
       "8175  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "8176  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "8177  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "8178  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "8179  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   \n",
       "\n",
       "                                                   text  \n",
       "0     RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...  \n",
       "1     RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...  \n",
       "2     RT @taqa_sa: Ø§Ù„Ø¬Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ø§Ø± ÙˆØ§Ù„Ø£Ø®Ø¶Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø­Ù…...  \n",
       "3     RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...  \n",
       "4     RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...  \n",
       "...                                                 ...  \n",
       "8175  RT @taqa_sa: Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#...  \n",
       "8176  RT @taqa_sa: Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#...  \n",
       "8177  Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¶Ø± Ø¹Ø²ÙÙƒ Ù…Ø¯ÙˆØ²Ù† ÙˆÙŠØ·Ø±Ø¨ ğŸ¼\\n\\n#ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª\\n...  \n",
       "8178  #ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª\\nØ­Ø¨Ù‘ÙŠØª Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠ â¤ï¸â¤ï¸ http...  \n",
       "8179               #ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª https://t.co/LleXgDcyqg  \n",
       "\n",
       "[8180 rows x 16 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add id column in the dataset, so it will help us when we merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df[\"id\"] = df.index \n",
    "#newdata.head()\n",
    "df.columns= df.columns.str.lower()\n",
    "df.columns\n",
    "df.drop(['index'], axis=1  , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the data into 2, data1 for sentiment then will merge with data2 for analysis\n",
    "\n",
    "- data2 contain ('screen_name','text','id')\n",
    "- data1 contain all other coulmns + id for merge later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M_World2020</td>\n",
       "      <td>RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B7Kgsvd72R2jzNL</td>\n",
       "      <td>RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abohedab1</td>\n",
       "      <td>RT @taqa_sa: Ø§Ù„Ø¬Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ø§Ø± ÙˆØ§Ù„Ø£Ø®Ø¶Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø­Ù…...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanoma29441020</td>\n",
       "      <td>RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560Mohammad</td>\n",
       "      <td>RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  id\n",
       "0      M_World2020  RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...   0\n",
       "1  B7Kgsvd72R2jzNL  RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...   1\n",
       "2        Abohedab1  RT @taqa_sa: Ø§Ù„Ø¬Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¯Ø§Ø± ÙˆØ§Ù„Ø£Ø®Ø¶Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø­Ù…...   2\n",
       "3   Hanoma29441020  RT @taqa_sa: Ø¬Ù…Ø¹Ù†Ø§ Ù„ÙƒÙ… Ø£Ù‡Ù… Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† ...   3\n",
       "4      560Mohammad  RT @M_World2020: https://t.co/nyyt4s0bsG\\n#Ø¨Ù„Ø§...   4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = df[[\"screen_name\",'text','id']] \n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df.copy()\n",
    "data1.drop(['screen_name', 'text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             Ù‘    | # Tashdid\n",
    "                             Ù    | # Fatha\n",
    "                             Ù‹    | # Tanwin Fath\n",
    "                             Ù    | # Damma\n",
    "                             ÙŒ    | # Tanwin Damm\n",
    "                             Ù    | # Kasra\n",
    "                             Ù    | # Tanwin Kasr\n",
    "                             Ù’    | # Sukun\n",
    "                             Ù€     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
    "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "\n",
    "# def space(text):\n",
    "#     text= re.sub(r\"_\", '\\s+', s)\n",
    "#     return text\n",
    "\n",
    "# new1['text'].replace('_', ' ', regex=True, inplace=True)\n",
    "\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def remove_hashtag(text):\n",
    "    return text.replace(\"#\\\\p{IsAlphabetic}+\", \"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPost(tweet):\n",
    "\n",
    "    #Replace @username with empty string\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet)\n",
    "    \n",
    "    #Replace RT with empty string\n",
    "    tweet = re.sub('RT', ' ', tweet)\n",
    "    \n",
    "    #Convert www.* or https?://* to \" \"\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',tweet)\n",
    "    \n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    \n",
    "    \n",
    "    #remove non-arabic\n",
    "#      tweet = re.sub(r'[^Ø¡-ÙŠ0-9]',' ',tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "<ipython-input-86-cce51f8418ad>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text'] = data2['text'].str.replace(r'\\d+','')\n",
      "<ipython-input-86-cce51f8418ad>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']= data2['text'].apply(lambda x: remove_diacritics(x))\n",
      "<ipython-input-86-cce51f8418ad>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']= data2['text'].apply(lambda x: remove_repeating_char(x))\n",
      "<ipython-input-86-cce51f8418ad>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']= data2['text'].apply(lambda x: processPost(x))\n",
      "<ipython-input-86-cce51f8418ad>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']= data2['text'].apply(lambda x: remove_hashtag(x))\n",
      "<ipython-input-86-cce51f8418ad>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']= data2['text'].apply(lambda x: remove_punctuations(x))\n",
      "<ipython-input-86-cce51f8418ad>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text']=data2['text'].apply(lambda x: remove_repeating_char(x))\n"
     ]
    }
   ],
   "source": [
    "data2['text'].replace('[^Ø¡-ÙŠ0-9]', ' ', regex=True, inplace=True)\n",
    "\n",
    "data2['text'].replace('_', ' ', regex=True, inplace=True)\n",
    "\n",
    "data2['text'] = data2['text'].str.replace(r'\\d+','')\n",
    "\n",
    "data2['text']= data2['text'].apply(lambda x: remove_diacritics(x))\n",
    "\n",
    "data2['text']= data2['text'].apply(lambda x: remove_repeating_char(x))\n",
    "\n",
    "data2['text']= data2['text'].apply(lambda x: processPost(x))\n",
    "\n",
    "data2['text']= data2['text'].apply(lambda x: remove_hashtag(x))\n",
    "\n",
    "data2['text']= data2['text'].apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "data2['text']=data2['text'].apply(lambda x: remove_repeating_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-47580ab5b55e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text'] = data2['text'].apply(tokens.tokenize)\n"
     ]
    }
   ],
   "source": [
    "tokens = TweetTokenizer()\n",
    "data2['text'] = data2['text'].apply(tokens.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = ['Ø¥Ø°', 'Ø¥Ø°Ø§', 'Ø¥Ø°Ù…Ø§', 'Ø¥Ø°Ù†', 'Ø£Ù', 'Ø£Ù‚Ù„', 'Ø£ÙƒØ«Ø±', 'Ø£Ù„Ø§', 'Ø¥Ù„Ø§', 'Ø§Ù„ØªÙŠ', 'Ø§Ù„Ø°ÙŠ', 'Ø§Ù„Ø°ÙŠÙ†', 'Ø§Ù„Ù„Ø§ØªÙŠ', 'Ø§Ù„Ù„Ø§Ø¦ÙŠ', 'Ø§Ù„Ù„ØªØ§Ù†', 'Ø§Ù„Ù„ØªÙŠØ§', 'Ø§Ù„Ù„ØªÙŠÙ†', 'Ø§Ù„Ù„Ø°Ø§Ù†', 'Ø§Ù„Ù„Ø°ÙŠÙ†', 'Ø§Ù„Ù„ÙˆØ§ØªÙŠ', 'Ø¥Ù„Ù‰', 'Ø¥Ù„ÙŠÙƒ', 'Ø¥Ù„ÙŠÙƒÙ…', 'Ø¥Ù„ÙŠÙƒÙ…Ø§', 'Ø¥Ù„ÙŠÙƒÙ†', 'Ø£Ù…', 'Ø£Ù…Ø§', 'Ø£Ù…Ø§', 'Ø¥Ù…Ø§', 'Ø£Ù†', 'Ø¥Ù†', 'Ø¥Ù†Ø§', 'Ø£Ù†Ø§', 'Ø£Ù†Øª', 'Ø£Ù†ØªÙ…', 'Ø£Ù†ØªÙ…Ø§', 'Ø£Ù†ØªÙ†', 'Ø¥Ù†Ù…Ø§', 'Ø¥Ù†Ù‡', 'Ø£Ù†Ù‰', 'Ø£Ù†Ù‰', 'Ø¢Ù‡', 'Ø¢Ù‡Ø§', 'Ø£Ùˆ', 'Ø£ÙˆÙ„Ø§Ø¡', 'Ø£ÙˆÙ„Ø¦Ùƒ', 'Ø£ÙˆÙ‡', 'Ø¢ÙŠ', 'Ø£ÙŠ', 'Ø£ÙŠÙ‡Ø§', 'Ø¥ÙŠ', 'Ø£ÙŠÙ†', 'Ø£ÙŠÙ†', 'Ø£ÙŠÙ†Ù…Ø§', 'Ø¥ÙŠÙ‡', 'Ø¨Ø®', 'Ø¨Ø³', 'Ø¨Ø¹Ø¯', 'Ø¨Ø¹Ø¶', 'Ø¨Ùƒ', 'Ø¨ÙƒÙ…', 'Ø¨ÙƒÙ…', 'Ø¨ÙƒÙ…Ø§', 'Ø¨ÙƒÙ†', 'Ø¨Ù„', 'Ø¨Ù„Ù‰', 'Ø¨Ù…Ø§', 'Ø¨Ù…Ø§Ø°Ø§', 'Ø¨Ù…Ù†', 'Ø¨Ù†Ø§', 'Ø¨Ù‡', 'Ø¨Ù‡Ø§', 'Ø¨Ù‡Ù…', 'Ø¨Ù‡Ù…Ø§', 'Ø¨Ù‡Ù†', 'Ø¨ÙŠ', 'Ø¨ÙŠÙ†','Ùˆ', 'Ø¨ÙŠØ¯',\n",
    "         'ØªÙ„Ùƒ', 'ØªÙ„ÙƒÙ…', 'ØªÙ„ÙƒÙ…Ø§', 'ØªÙ‡', 'ØªÙŠ', 'ØªÙŠÙ†', 'ØªÙŠÙ†Ùƒ',\n",
    "         'Ø«Ù…', 'Ø«Ù…Ø©', 'Ø­Ø§Ø´Ø§', 'Ø­Ø¨Ø°Ø§', 'Ø­ØªÙ‰', 'Ø­ÙŠØ«', 'Ø­ÙŠØ«Ù…Ø§',\n",
    "         'Ø­ÙŠÙ†', 'Ø®Ù„Ø§', 'Ø¯ÙˆÙ†', 'Ø°Ø§', 'Ø°Ø§Øª', 'Ø°Ø§Ùƒ', 'Ø°Ø§Ù†', 'Ø°Ø§Ù†Ùƒ', 'Ø°Ù„Ùƒ',\n",
    "         'Ø°Ù„ÙƒÙ…', 'Ø°Ù„ÙƒÙ…Ø§', 'Ø°Ù„ÙƒÙ†', 'Ø°Ù‡', 'Ø°Ùˆ', 'Ø°ÙˆØ§', 'Ø°ÙˆØ§ØªØ§',\n",
    "         'Ø°ÙˆØ§ØªÙŠ', 'Ø°ÙŠ', 'Ø°ÙŠÙ†', 'Ø°ÙŠÙ†Ùƒ', 'Ø±ÙŠØ«', 'Ø³ÙˆÙ', 'Ø³ÙˆÙ‰', 'Ø´ØªØ§Ù†', 'Ø¹Ø¯Ø§',\n",
    "         'Ø¹Ø³Ù‰', 'Ø¹Ù„', 'Ø¹Ù„Ù‰', 'Ø¹Ù„ÙŠÙƒ', 'Ø¹Ù„ÙŠÙ‡', 'Ø¹Ù…Ø§', 'Ø¹Ù†', 'Ø¹Ù†Ø¯', 'ØºÙŠØ±',\n",
    "         'ÙØ¥Ø°Ø§', 'ÙØ¥Ù†', 'ÙÙ„Ø§', 'ÙÙ…Ù†', 'ÙÙŠ', 'ÙÙŠÙ…', 'ÙÙŠÙ…Ø§', 'ÙÙŠÙ‡', 'ÙÙŠÙ‡Ø§',\n",
    "         'Ù‚Ø¯', 'ÙƒØ£Ù†', 'ÙƒØ£Ù†Ù…Ø§', 'ÙƒØ£ÙŠ', 'ÙƒØ£ÙŠÙ†', 'ÙƒØ°Ø§', 'ÙƒØ°Ù„Ùƒ', 'ÙƒÙ„', 'ÙƒÙ„Ø§',\n",
    "         'ÙƒÙ„Ø§Ù‡Ù…Ø§', 'ÙƒÙ„ØªØ§', 'ÙƒÙ„Ù…Ø§', 'ÙƒÙ„ÙŠÙƒÙ…Ø§', 'ÙƒÙ„ÙŠÙ‡Ù…Ø§', 'ÙƒÙ…', 'ÙƒÙ…', 'ÙƒÙ…Ø§',\n",
    "         'ÙƒÙŠ', 'ÙƒÙŠØª', 'ÙƒÙŠÙ', 'ÙƒÙŠÙÙ…Ø§', 'Ù„Ø§', 'Ù„Ø§Ø³ÙŠÙ…Ø§', 'Ù„Ø¯Ù‰', 'Ù„Ø³Øª', 'Ù„Ø³ØªÙ…',\n",
    "         'Ù„Ø³ØªÙ…Ø§', 'Ù„Ø³ØªÙ†', 'Ù„Ø³Ù†', 'Ù„Ø³Ù†Ø§', 'Ù„Ø¹Ù„', 'Ù„Ùƒ', 'Ù„ÙƒÙ…', 'Ù„ÙƒÙ…Ø§',\n",
    "         'Ù„ÙƒÙ†', 'Ù„ÙƒÙ†Ù…Ø§', 'Ù„ÙƒÙŠ', 'Ù„ÙƒÙŠÙ„Ø§', 'Ù„Ù…', 'Ù„Ù…Ø§', 'Ù„Ù†', 'Ù„Ù†Ø§',\n",
    "         'Ù„Ù‡', 'Ù„Ù‡Ø§', 'Ù„Ù‡Ù…', 'Ù„Ù‡Ù…Ø§', 'Ù„Ù‡Ù†', 'Ù„Ùˆ', 'Ù„ÙˆÙ„Ø§', 'Ù„ÙˆÙ…Ø§',\n",
    "         'Ù„ÙŠ', 'Ù„Ø¦Ù†', 'Ù„ÙŠØª', 'Ù„ÙŠØ³', 'Ù„ÙŠØ³Ø§', 'Ù„ÙŠØ³Øª', 'Ù„ÙŠØ³ØªØ§', 'Ù„ÙŠØ³ÙˆØ§', 'Ù…Ø§',\n",
    "         'Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ù…Ø°', 'Ù…Ø¹', 'Ù…Ù…Ø§', 'Ù…Ù…Ù†', 'Ù…Ù†', 'Ù…Ù†Ù‡', 'Ù…Ù†Ù‡Ø§', 'Ù…Ù†Ø°',\n",
    "         'Ù…Ù‡', 'Ù…Ù‡Ù…Ø§', 'Ù†Ø­Ù†', 'Ù†Ø­Ùˆ', 'Ù†Ø¹Ù…', 'Ù‡Ø§', 'Ù‡Ø§ØªØ§Ù†', 'Ù‡Ø§ØªÙ‡', 'Ù‡Ø§ØªÙŠ',\n",
    "         'Ù‡Ø§ØªÙŠÙ†', 'Ù‡Ø§Ùƒ', 'Ù‡Ø§Ù‡Ù†Ø§', 'Ù‡Ø°Ø§', 'Ù‡Ø°Ø§Ù†', 'Ù‡Ø°Ù‡', 'Ù‡Ø°ÙŠ', 'Ù‡Ø°ÙŠÙ†', 'Ù‡ÙƒØ°Ø§',\n",
    "         'Ù‡Ù„', 'Ù‡Ù„Ø§', 'Ù‡Ù…', 'Ù‡Ù…Ø§', 'Ù‡Ù†', 'Ù‡Ù†Ø§', 'Ù‡Ù†Ø§Ùƒ', 'Ù‡Ù†Ø§Ù„Ùƒ', 'Ù‡Ùˆ', 'Ù‡Ø¤Ù„Ø§Ø¡',\n",
    "         'Ù‡ÙŠ', 'Ù‡ÙŠØ§', 'Ù‡ÙŠØª', 'Ù‡ÙŠÙ‡Ø§Øª', 'ÙˆØ§Ù„Ø°ÙŠ', 'ÙˆØ§Ù„Ø°ÙŠÙ†', 'ÙˆØ¥Ø°', 'ÙˆØ¥Ø°Ø§', 'ÙˆØ¥Ù†',\n",
    "         'ÙˆÙ„Ø§', 'ÙˆÙ„ÙƒÙ†', 'ÙˆÙ„Ùˆ', 'ÙˆÙ…Ø§', 'ÙˆÙ…Ù†', 'ÙˆÙ‡Ùˆ', 'ÙŠØ§' , 'Ù…Ù†' , 'Ø¹Ù„Ù‰', 'Ø§Ù„Ù‰','Ù‡Ù…Ø§', 'Ù…Ø¹', 'Ù‡Ø°Ù‡', 'Ø§Ù„ØªÙŠ', 'ÙƒÙ…Ø§ ', 'Ø°Ù„Ùƒ ', 'Ù„Ø°Ø§', 'Ø¹Ù†', 'ÙÙŠ','Ø§Ù†','ÙƒØ§Ù†','ÙƒØ§Ù†Øª','Ø§Ù„Ù‰','Ù‚Ø¨Ù„','Ø£Ù†Ù‡','ØªÙ…'\n",
    "        ,'ÙˆÙ‚Ø§Ù„','Ù‚Ø§Ù„','ÙÙ‰','ÙˆÙ‚Ø¯','Ù‚Ø¯','ÙˆÙ„Ù…','ÙˆØ°Ù„Ùƒ','Ø°Ù„Ùƒ','ÙŠÙƒÙˆÙ†','Ø§Ùˆ','ÙˆÙ‡Ø°Ù‡','ÙˆÙ‡ÙŠ ','ÙˆØ¨Ø¹Ø¯','ÙˆÙ‡Ø°Ø§','Ø¹Ù†Ø¯Ù‡Ø§','Ø¬Ø¯Ø§','Ø¨Ø£Ù†','Ø§Ù†Ù‡','Ø§Ù„ÙŠ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-76566a917a86>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2['text'] = [w for w in data2['text'] if not w in stop]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M_World2020</td>\n",
       "      <td>[Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B7Kgsvd72R2jzNL</td>\n",
       "      <td>[Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abohedab1</td>\n",
       "      <td>[Ø§Ù„Ø¬Ø§Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø¯Ø§Ø±, ÙˆØ§Ù„Ø£Ø®Ø¶Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø£Ø­Ù…Ø±, ÙˆÙØ±Øª...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanoma29441020</td>\n",
       "      <td>[Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560Mohammad</td>\n",
       "      <td>[Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name                                               text  id\n",
       "0      M_World2020  [Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...   0\n",
       "1  B7Kgsvd72R2jzNL  [Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...   1\n",
       "2        Abohedab1  [Ø§Ù„Ø¬Ø§Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø¯Ø§Ø±, ÙˆØ§Ù„Ø£Ø®Ø¶Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø£Ø­Ù…Ø±, ÙˆÙØ±Øª...   2\n",
       "3   Hanoma29441020  [Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...   3\n",
       "4      560Mohammad  [Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...   4"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['text'] = [w for w in data2['text'] if not w in stop]\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-92-49ccc506c286>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[\"is_spam\"] = data2['text'].apply(lambda x: remove_noise(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ok    8178\n",
       "Name: is_spam, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the bad tweets\n",
    "\n",
    "spam =[\"Ø­Ø³Ø¨ Ø§Ù„Ø·Ù„Ø¨\", \"Ù„Ù„ØªÙˆØ§ØµÙ„\" , \"ØªÙ†ÙÙŠØ° Ø¨Ø§Ù„Ø§Ø³Ù…Ø§Ø¡\", \"Ø§Ø¯Ø®Ù„ Ø§Ù„Ø³Ø­Ø¨\",\"Ù…Ø³Ø§Ø¬\",\"Ø³Ø­ÙˆØ¨Ø§Øª\"]\n",
    "\n",
    "def remove_noise(tweet):\n",
    "    label=\"ok\"\n",
    "    for word in spam:\n",
    "        if word in tweet:\n",
    "            label=\"spam\"\n",
    "\n",
    "    return label\n",
    "\n",
    "data2[\"is_spam\"] = data2['text'].apply(lambda x: remove_noise(x))\n",
    "\n",
    "data2.is_spam.value_counts()\n",
    "\n",
    "data2=data2[data2[\"is_spam\"]!=\"spam\"]\n",
    "\n",
    "data2.is_spam.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading the positive lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df=pd.read_csv(\"pos.list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=pos_df[\"Word\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_sentiment(tweet):\n",
    "    \n",
    "    count=0\n",
    "    # loop through the list of words and see if they are in the tweet text\n",
    "    for word in pos_list:\n",
    "        \n",
    "        if word in tweet:\n",
    "            count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"pos_count\"] = data2['text'].apply(lambda x: pos_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading the negative lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.read_csv(\"neg.list.csv\", 'w', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø§Ù„ØºÙŠØ± Ø§Ø®Ù„Ø§Ù‚ÙŠÙ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø§Ø¨Ø­ÙˆÙ„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø§Ø¨Ù„Øº Ø¹Ù„ÙŠÙƒÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø§Ø¨Ùˆ Ø´ÙƒÙ„Ùƒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø§Ø¨Ùˆ ÙƒÙ„Ø¨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word\n",
       "0  Ø§Ù„ØºÙŠØ± Ø§Ø®Ù„Ø§Ù‚ÙŠÙ‡\n",
       "1          Ø§Ø¨Ø­ÙˆÙ„\n",
       "2     Ø§Ø¨Ù„Øº Ø¹Ù„ÙŠÙƒÙ…\n",
       "3       Ø§Ø¨Ùˆ Ø´ÙƒÙ„Ùƒ\n",
       "4        Ø§Ø¨Ùˆ ÙƒÙ„Ø¨"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_list=neg_df[\"Word\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sentiment(tweet):\n",
    "    \n",
    "    count=0\n",
    "     # loop through the list of words and see if they are in the tweet text\n",
    "    for word in neg_list:\n",
    "        if word in tweet:\n",
    "            count+=1\n",
    "               \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"neg_count\"] = data2['text'].apply(lambda x: neg_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment(tweet):\n",
    "    \n",
    "    pos_sent=pos_sentiment(tweet)\n",
    "    \n",
    "    neg_sent=neg_sentiment(tweet)\n",
    "    \n",
    "    if pos_sent > neg_sent:\n",
    "        label = \"Positive\"\n",
    "    \n",
    "    elif pos_sent < neg_sent:\n",
    "        label = \"Negative\"\n",
    "    else:\n",
    "        label = \"Neutral\" \n",
    "   \n",
    "   \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"sentiment\"] = data2['text'].apply(lambda x: tweet_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we have the sentiment column, we drop the 'pos_count', 'neg_count' we don't need it in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(['pos_count', 'neg_count'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we join data1 and data2, the rest is all about visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your team can delete unnecessary columns like: tokens, etc...\n",
    "final_data = data1.merge(data2,on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codes to help cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.duplicated().sum\n",
    "\n",
    "final_data = final_data.drop_duplicates()\n",
    "\n",
    "final_data.tail()\n",
    "\n",
    "final_data.duplicated().sum()\n",
    "\n",
    "final_data.info()\n",
    "\n",
    "final_data.tail(3)\n",
    "\n",
    "final_data.info()\n",
    "\n",
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we orgnaize the dataset and help in visulaized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.rename({'in_reply_to_screen_name': 'replied_to'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not given                        4617\n",
       "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©          876\n",
       "Ø¬Ø¯Ø©, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©     234\n",
       "Ø§Ù„Ø±ÙŠØ§Ø¶                            204\n",
       "Kingdom of Saudi Arabia           149\n",
       "                                 ... \n",
       "Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠÙ‡                     1\n",
       "Ù†Ø¬Ø±Ø§Ù† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©                      1\n",
       "Pakistan                            1\n",
       "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡            1\n",
       "26.479816,50.051769                 1\n",
       "Name: location, Length: 807, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code find thr location\n",
    "\n",
    "final_data['location'].fillna(\"Not given\", inplace=True)\n",
    "final_data['replied_to'].fillna(\"nan\", inplace=True)\n",
    "final_data['in_reply_to_user_id_str'].fillna(\"nan\", inplace=True)\n",
    "final_data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>replied_to</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>addition_data</th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Nov 24 19:10:31 +0000 2020</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>17</td>\n",
       "      <td>Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...</td>\n",
       "      <td>0</td>\n",
       "      <td>M_World2020</td>\n",
       "      <td>[Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...</td>\n",
       "      <td>ok</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Nov 24 19:08:33 +0000 2020</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>22</td>\n",
       "      <td>Not given</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>1</td>\n",
       "      <td>B7Kgsvd72R2jzNL</td>\n",
       "      <td>[Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...</td>\n",
       "      <td>ok</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Nov 24 19:00:02 +0000 2020</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>301</td>\n",
       "      <td>Not given</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>2</td>\n",
       "      <td>Abohedab1</td>\n",
       "      <td>[Ø§Ù„Ø¬Ø§Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø¯Ø§Ø±, ÙˆØ§Ù„Ø£Ø®Ø¶Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø£Ø­Ù…Ø±, ÙˆÙØ±Øª...</td>\n",
       "      <td>ok</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Nov 24 18:42:07 +0000 2020</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>69</td>\n",
       "      <td>Not given</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...</td>\n",
       "      <td>3</td>\n",
       "      <td>Hanoma29441020</td>\n",
       "      <td>[Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...</td>\n",
       "      <td>ok</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Nov 24 18:41:22 +0000 2020</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>87</td>\n",
       "      <td>Not given</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...</td>\n",
       "      <td>4</td>\n",
       "      <td>560Mohammad</td>\n",
       "      <td>[Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...</td>\n",
       "      <td>ok</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at               source  followers_count  \\\n",
       "0  Tue Nov 24 19:10:31 +0000 2020  Twitter for Android               17   \n",
       "1  Tue Nov 24 19:08:33 +0000 2020   Twitter for iPhone               22   \n",
       "2  Tue Nov 24 19:00:02 +0000 2020  Twitter for Android              301   \n",
       "3  Tue Nov 24 18:42:07 +0000 2020  Twitter for Android               69   \n",
       "4  Tue Nov 24 18:41:22 +0000 2020  Twitter for Android               87   \n",
       "\n",
       "                   location  verified replied_to in_reply_to_user_id_str  \\\n",
       "0  Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©     False        nan                     nan   \n",
       "1                 Not given     False        nan                     nan   \n",
       "2                 Not given     False        nan                     nan   \n",
       "3                 Not given     False        nan                     nan   \n",
       "4                 Not given     False        nan                     nan   \n",
       "\n",
       "   reply_count  retweet_count  favorite_count lang  favorited  retweeted  \\\n",
       "0            0              0               0  und      False      False   \n",
       "1            0              0               0   ar      False      False   \n",
       "2            0              0               0   ar      False      False   \n",
       "3            0              0               0   ar      False      False   \n",
       "4            0              0               0  und      False      False   \n",
       "\n",
       "                                       addition_data  id      screen_name  \\\n",
       "0  {'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...   0      M_World2020   \n",
       "1  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   1  B7Kgsvd72R2jzNL   \n",
       "2  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   2        Abohedab1   \n",
       "3  {'hashtags': [{'text': 'ÙˆÙØ±Øª_ÙˆØ£Ù†ÙˆØ±Øª', 'indices...   3   Hanoma29441020   \n",
       "4  {'hashtags': [{'text': 'Ø¨Ù„Ø§Ùƒ_ÙØ±Ø§ÙŠØ¯ÙŠ_Ø´ÙŠ_Ø¥Ù†', 'i...   4      560Mohammad   \n",
       "\n",
       "                                                text is_spam sentiment  \n",
       "0  [Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...      ok   Neutral  \n",
       "1  [Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...      ok   Neutral  \n",
       "2  [Ø§Ù„Ø¬Ø§Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø¯Ø§Ø±, ÙˆØ§Ù„Ø£Ø®Ø¶Ø±, Ù‚Ø¨Ù„, Ø§Ù„Ø£Ø­Ù…Ø±, ÙˆÙØ±Øª...      ok   Neutral  \n",
       "3  [Ø¬Ù…Ø¹Ù†Ø§, Ù„ÙƒÙ…, Ø£Ù‡Ù…, Ø§Ù„Ù†ØµØ§Ø¦Ø­, Ù„ØªÙ‚Ù„ÙŠÙ„, Ù…Ù†, Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ...      ok   Neutral  \n",
       "4  [Ø¨Ù„Ø§Ùƒ, ÙØ±Ø§ÙŠØ¯ÙŠ, Ø´ÙŠ, Ø¥Ù†, Ø¬Ø§Ù…Ø¹Ø©, Ø§Ù„Ø­ÙØ±, Ø¹Ù†, Ø¨Ø¹Ø¯, ...      ok   Neutral  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the source \n",
    "\n",
    "final_data[\"source\"] = final_data[\"source\"].str.extract('>(.+?)<', expand=False).str.strip() \n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### change to date type, datetime and subset by weeks and days\n",
    "\n",
    "final_data['created_at'] = pd.to_datetime(final_data.created_at)\n",
    "\n",
    "import pytz\n",
    "\n",
    "#all date comes in UTC\n",
    "#change dattime to saudi arabia \n",
    "\n",
    "final_data.created_at = final_data.created_at.dt.tz_convert('Asia/Riyadh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type and create new columns\n",
    "\n",
    "final_data['followers_count'] = final_data['followers_count'].astype(int)\n",
    "final_data['reply_count']= final_data['reply_count'].astype(int)\n",
    "final_data['retweet_count']= final_data['retweet_count'].astype(int)\n",
    "final_data['favorite_count']= final_data['favorite_count'].astype(int)\n",
    "\n",
    "\n",
    "final_data['replied_to']= final_data['replied_to'].astype(str)\n",
    "final_data['in_reply_to_user_id_str']= final_data['in_reply_to_user_id_str'].astype(str)\n",
    "\n",
    "final_data['by_hours'] = final_data.created_at.dt.hour\n",
    "final_data['by_day'] = final_data.created_at.dt.day_name()\n",
    "final_data['by_month'] = final_data.created_at.dt.month\n",
    "final_data['by_year'] = final_data.created_at.dt.year\n",
    "\n",
    "final_data['by_hours'] = final_data['by_hours'].replace([4,5,6,7,8,9,10,11], \"Morning\")\n",
    "final_data['by_hours'] = final_data['by_hours'].replace([12,13,14,15,16], \"AfterNoon\")\n",
    "final_data['by_hours'] = final_data['by_hours'].replace([17, 18, 19,20,21], \"Evening\")\n",
    "final_data['by_hours'] = final_data['by_hours'].replace([22,23,0,1,2,3,], \"night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### after the cleaning find it it is retweet or non retweet\n",
    "\n",
    "noise=[\"RT\"]\n",
    "\n",
    "def find_rt(tweet):\n",
    "    label=\"Not a Retweet\"\n",
    "    for word in noise:\n",
    "        if word in tweet:\n",
    "            label=\"Retweet\"\n",
    "\n",
    "    return label\n",
    "\n",
    "final_data[\"retweet\"] = final_data['text'].apply(lambda x: find_rt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will find the number of replies to our acc (@taga_sa)\n",
    "\n",
    "def find_replies(data):\n",
    "    if data[\"replied_to\"] == \"taqa_sa\":\n",
    "        return \"Yes\"\n",
    "    elif data[\"replied_to\"] == \"nan\":\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "\n",
    "final_data = final_data.assign(replies_to=final_data.apply(find_replies, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where people tweet from:\n",
      "Twitter for iPhone                  4245\n",
      "Twitter for Android                 3332\n",
      "Twitter Web App                      360\n",
      "Twitter for iPad                     151\n",
      "TweetDeck                             20\n",
      "PlumeÂ forÂ Android                     17\n",
      "Twitter Ads                           11\n",
      "Twitter Media Studio                  11\n",
      "Sprinklr                              10\n",
      "Twitter for Advertisers                3\n",
      "Twitter Media Studio - LiveCut         3\n",
      "Tweetbot for iÎŸS                       3\n",
      "Twitter for Advertisers (legacy)       2\n",
      "moustahlek                             1\n",
      "sra7h.com                              1\n",
      "samhnews                               1\n",
      "Hashflags                              1\n",
      "WordPress.com                          1\n",
      "eClincher                              1\n",
      "XboxInfos                              1\n",
      "application999999999                   1\n",
      "IFTTT                                  1\n",
      "Hootsuite Inc.                         1\n",
      "Name: source, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "favorite_count    334\n",
       "retweet_count      17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more information will be shown as visual\n",
    "\n",
    "final_data[final_data['replied_to'] == 'taga_sa']\n",
    "\n",
    "final_data['replied_to'].value_counts()\n",
    "\n",
    "final_data.replies_to.value_counts()\n",
    "\n",
    "\n",
    "\n",
    "final_data.retweet.value_counts()\n",
    "\n",
    "final_data['reply_count'].sum()\n",
    "\n",
    "final_data['verified'].value_counts()\n",
    "\n",
    "final_data['replied_to'].value_counts()\n",
    "\n",
    "final_data.nlargest(3, ['reply_count']) \n",
    "\n",
    "final_data.nlargest(10, ['favorite_count']) \n",
    "\n",
    "final_data.nlargest(5, ['retweet_count']) \n",
    "\n",
    "final_data.source.value_counts().sum()\n",
    "\n",
    "print('where people tweet from:\\n{}'.format(final_data.source.value_counts()))\n",
    "\n",
    "\n",
    "\n",
    "final_data.by_day.value_counts()\n",
    "\n",
    "final_data.by_hours.value_counts()\n",
    "\n",
    "\n",
    "final_data = final_data[final_data['replies_to'] == \"Yes\"]\n",
    "\n",
    "\n",
    "final_data['retweeted'].value_counts()\n",
    "\n",
    "final_data['retweet'].value_counts()\n",
    "\n",
    "final_data['retweet_count'].sum()\n",
    "\n",
    "final_data['favorited'].value_counts()\n",
    "\n",
    "final_data['favorite_count'].sum()\n",
    "\n",
    "final_data[['favorite_count','retweet_count']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find catograize the tweet\n",
    "\n",
    "acting_and_Ads =[\"ÙŠÙˆØ³Ù\",\"Ø§Ù„Ø¬Ø±Ø§Ø­\",\"ØªÙ…Ø«ÙŠÙ„\",\"Ù…Ù…Ø«Ù„\", \"Ø¥Ø¹Ù„Ø§Ù†\", \"Ø§Ø¹Ù„Ø§Ù†\", \"Ø±ÙˆØ¹Ø©\", \"Ø§Ù„Ø§Ø¹Ù„Ø§Ù†\",\"Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†\", \"Ø±Ù‡ÙŠØ¨\", \"ğŸ˜‚\", \"ğŸ˜‚â¤ï¸\",\"â¤ï¸\", \"Ø§Ù„Ø­Ù„Ùˆ\", \n",
    "        \"ÙÙ†Ù†Ø§Ø§Ù†\",\"Ø­Ø­Ù„ÙˆÙˆ\", \"ğŸ¤£\",\"ğŸ’š\", \"Ø§Ù„Ø­Ù„Ùˆ\", \"Ø§Ù„ÙÙ†Ø§Ù†\", \"Ù…Ø³Ù„Ø³Ù„Ø§ØªÙ‡\", \"Ø¯Ø¹Ø§ÙŠØ©\", \"Ø§Ø¨Ø¯Ø§Ø¹\", \"Ø¬Ù‡ÙˆØ¯ÙƒÙ…\",\"ğŸ‘\",\"Ø§Ø¨Ø¯Ø§Ø¹\" ]\n",
    "\n",
    "compliments = [\"ğŸ‘\",\"ğŸŒ¹\",\"Ø§Ù„Ø±Ø¯ÙˆØ¯\" , \"Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©\", \"Ø¬Ù‡ÙˆØ¯ÙƒÙ…\", \"Ø§Ù„ØªÙˆØ¹ÙŠÙ‡\", \"Ø¬Ù…ÙŠÙ„\",\"ÙŠØ¹Ø·ÙŠÙƒÙ…\",\"Ø­Ø¨ÙŠØª\",\n",
    "               \"Ø´ÙƒØ±Ø§\", \"Ø´ÙƒØ±Ø§ Ù„ÙƒÙ…\", \"Ø§Ø­ØªØ±Ø§ÙÙŠ\", \"ØªÙ…Ø§Ù…\",\"Ø§Ù„Ø¹Ø§ÙÙŠØ©\",\"Ø¬Ù†Ø§Ù†\",\"Ø­Ø¨ÙŠØªÙƒÙ…\",\"ØªØ´ÙƒØ±ÙˆÙ†\"]\n",
    "\n",
    "complaint = [\"Ø§Ù„Ù„ÙŠØ¯\",\"Ø§Ù„ÙŠØ¯\",\"Ù…Ø§ÙÙŠØ©\",\"Ù…Ø§ÙÙŠÙ‡\", \"Ø§Ù„Ø³ÙˆÙ‚\",\"Ø®Ù„ØµØª\", \"ØºÙŠØ±Ùˆ\", \"Ø§Ù„Ø¯Ù‚ÙˆÙ†\",\"Ù…Ø§Ø§ØµØ¯Ù‚ÙƒÙ…\", \"Ø­Ø±Ø§Ù…ÙŠØ©\",\"Ø§Ø³ØºÙØ±\"\n",
    "            ,\"ØªØ®Ø±Ø¨\", 'Ù…ØªÙˆÙØ±Ø©', \"Ù…ØªÙˆÙØ±Ù‡\", \"Ù…Ø®Ù„ØµØ©\", \"Ù…Ø§Ù„Ù‚ÙŠØª\",\"Ø§Ù„Ø¯Ù‚ÙˆÙ†\", \"ØµØ¯Ù‚ØªÙƒÙ…\", \"Ù„Ø§Ø­ÙˆÙ„\",\"Ù„Ù„Ø§Ø³Ù\",\"ÙƒØ°Ø¨\"]\n",
    "\n",
    "Religion = [\"Ù…ÙˆØ³ÙŠÙ‚Ù‰\", \"Ø­Ø±Ø§Ù…\",\"Ø§Ù„Ø´Ø±Ø¹\",\"Ù…Ø§ÙŠØ¬ÙˆØ²\",\"Ø§Ø³ØºÙØ±\", \"Ù„Ø§Ø­ÙˆÙ„\",\"Ù„Ù„Ø§Ø³Ù\",\"ÙˆØ§Ù„Ø¹ÙŠØ§Ø°\"]\n",
    "\n",
    "def setcategory(tweet):\n",
    "    label=\"Others\"\n",
    "    for word in acting:\n",
    "        if word in tweet:\n",
    "            label=\"acting\"\n",
    "            \n",
    "        for word in compliments:\n",
    "            if word in tweet:\n",
    "                label=\"compliments\"\n",
    "            \n",
    "            for word in complaint:\n",
    "                if word in tweet:\n",
    "                    label=\"compline\"\n",
    "                    \n",
    "                for word in ads:\n",
    "                    if word in tweet:\n",
    "                        label=\"ads\"\n",
    "                    \n",
    "            \n",
    "    return label\n",
    "\n",
    "final_data[\"category\"] = final_data['text'].apply(lambda x: setcategory(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
